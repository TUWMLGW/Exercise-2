{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8770dafd",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac560308",
   "metadata": {},
   "source": [
    "This notebook serves as a comprehensive solution to Exercise 2 of the VU Machine Learning course (Summer Semester 2025). The primary objective of this exercise is to deepen our understanding of Neural Networks (NNs) by implementing them using various approaches and conducting a thorough comparative analysis. All approaches are applied to the [Polish Bankruptcies Dataset](https://archive.ics.uci.edu/dataset/365/polish+companies+bankruptcy+data) as well as the [Second Dataset]().\n",
    "\n",
    "Throughout this notebook, for each of the above mentioned datasets, we will:\n",
    "\n",
    "- Implement a Neural Network framework from scratch: The architecture, backward and forward propagation and the entire network are built within the **nn** folder in this repo.\n",
    "\n",
    "- Implement the same Neural Network using PyTorch: We leverage PyTorch's standard functions to create an equivalent NN, showcasing a more conventional approach to NN development.\n",
    "\n",
    "- Utilize an LLM tool for NN implementation: Using ChatGPT 4o to generate another version of the NN from scratch, allowing for a direct comparison of code structure, design choices, and potential differences with our custom implementation.\n",
    "\n",
    "- Investigate and experiment with NN configurations: We explore various hyperparameters, including different activation functions, numbers of layers, and nodes per layer, using a grid search approach to find optimal values.\n",
    "\n",
    "- Analyze performance and resource usage: We calculate the total number of learnable parameters and the virtual RAM consumed by our instantiated NNs.\n",
    "\n",
    "- Conduct a detailed comparison: The core of this notebook involves comparing the performance, efficiency, and implementation details across our custom-built NN, the PyTorch version, and the LLM-generated code. We discuss findings related to classification performance metrics and the insights gained from each implementation method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0438c519",
   "metadata": {},
   "source": [
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff3dce91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc1d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import requests\n",
    "import io\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from  nn.nn import NN\n",
    "from nn.layer import Layer\n",
    "from nn.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1699d0bb",
   "metadata": {},
   "source": [
    "## MNIST Dataset (How to use the custom NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a33f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv(\"train.csv\")\n",
    "split = int(len(mnist)*0.8)\n",
    "\n",
    "y_train, y_test = mnist[\"label\"].values[:split].astype(int), mnist[\"label\"].values[split:].astype(int)\n",
    "X_train, X_test = mnist.drop(\"label\", axis=1).values[:split], mnist.drop(\"label\", axis=1).values[split:]\n",
    "\n",
    "y_train_encoded = one_hot_encoding(y_train, 10)\n",
    "y_test_encoded = one_hot_encoding(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df0f0f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:02<00:09,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 ============ Loss: 0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:04<00:06,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 ============ Loss: 0.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:06<00:03,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 ============ Loss: 0.037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:08<00:01,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 ============ Loss: 0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:10<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 ============ Loss: 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    Layer(input_size=X_train.shape[1], output_size=10, activation_function='softmax'),\n",
    "    # Layer(input_size=10, output_size=10, activation_function='softmax'),\n",
    "]\n",
    "\n",
    "# Initialize the neural network\n",
    "nn = NN(layers=layers, num_classes = 10, activation_function='softmax', loss_function='cross_entropy')\n",
    "\n",
    "# Train the network\n",
    "epochs = 5\n",
    "nn.train(X_train, y_train_encoded, epochs=epochs, batch_size=100, learning_rate=0.1, verbose=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702ac350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': np.float64(2.5090297915988944),\n",
       " 'accuracy': np.float64(0.9091666666666667),\n",
       " 'precision': np.float64(0.9085492565199148),\n",
       " 'recall': np.float64(0.908163941302714),\n",
       " 'f1_score': np.float64(0.9078221584260732)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(X_test, y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6282b702",
   "metadata": {},
   "source": [
    "## Polish Bankruptcy Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f42f7d",
   "metadata": {},
   "source": [
    "### Analytics, Visualizations and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9bdae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b0ead08",
   "metadata": {},
   "source": [
    "### Custom NN Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c5c179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split_index = int(len(X) * 0.8)\n",
    "X_train = X[:train_test_split_index].values\n",
    "X_test = X[train_test_split_index:].values\n",
    "y_train = y[:train_test_split_index].values\n",
    "y_test = y[train_test_split_index:].values\n",
    "y_train_encoded = one_hot_encoding(y_train, 2)\n",
    "y_test_encoded = one_hot_encoding(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c213c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:00<00:02,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 ============ Loss: nan\n",
      "Epoch 2/20 ============ Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:00<00:02,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 ============ Loss: nan\n",
      "Epoch 4/20 ============ Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:00<00:02,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 ============ Loss: nan\n",
      "Epoch 6/20 ============ Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:01<00:01,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 ============ Loss: nan\n",
      "Epoch 8/20 ============ Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:01<00:01,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 ============ Loss: nan\n",
      "Epoch 10/20 ============ Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:01<00:01,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 ============ Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:01<00:01,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 ============ Loss: nan\n",
      "Epoch 13/20 ============ Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:02<00:00,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 ============ Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:02<00:01,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 ============ Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:02<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 ============ Loss: nan\n",
      "Epoch 17/20 ============ Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:03<00:00,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 ============ Loss: nan\n",
      "Epoch 19/20 ============ Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 ============ Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    Layer(input_size=X_train.shape[1], output_size=10, activation_function='sigmoid'),\n",
    "    Layer(input_size=10, output_size=4, activation_function='sigmoid'),\n",
    "    Layer(input_size=4, output_size=2, activation_function='sigmoid'),\n",
    "]\n",
    "\n",
    "# Initialize the neural network\n",
    "nn = NN(layers=layers, num_classes = 2, activation_function='sigmoid', loss_function='mean_squared_error')\n",
    "\n",
    "# Train the network\n",
    "epochs = 20\n",
    "nn.train(X_train, y_train_encoded, epochs=epochs, batch_size=1000, learning_rate=0.1, verbose=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a812f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': np.float64(nan),\n",
       " 'accuracy': np.float64(0.8934454555926736),\n",
       " 'precision': np.float64(0.4467227277963368),\n",
       " 'recall': np.float64(0.5),\n",
       " 'f1_score': np.float64(0.47186226196994585)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(X_test, y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e85bd",
   "metadata": {},
   "source": [
    "### Pytorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc2c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f0db885",
   "metadata": {},
   "source": [
    "### LLM Developed NN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92730b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a92cf547",
   "metadata": {},
   "source": [
    "### Comparison Across the Three Implemtations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd6ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f47dcbcf",
   "metadata": {},
   "source": [
    "## 2nd Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d63b5f",
   "metadata": {},
   "source": [
    "### Analytics, Visualization and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0585814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83a73802",
   "metadata": {},
   "source": [
    "### Custom NN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4992f4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56eb576a",
   "metadata": {},
   "source": [
    "### Pytorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a09ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d4279f1",
   "metadata": {},
   "source": [
    "### LLM Developed NN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036590a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc4a626a",
   "metadata": {},
   "source": [
    "### Comparison Across the Three Implemtations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1b6c07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
